{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from operator import itemgetter\n",
    "import tools as tl\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from matplotlib import pylab as plt\n",
    "from scipy.stats import entropy, norm\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data='melanoma'#or 'melanoma'\n",
    "method='unet_patch'\n",
    "model_name=\"unet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Directry を作る関数\n",
    "def my_makedirs(path):\n",
    "    if not os.path.isdir(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#正規分布に基づいたstep幅を決める関数\n",
    "sigma=0.4#0~1の間, 0.4がbest\n",
    "def gaussian_dist(sigma,max_step):\n",
    "    X = np.arange(0,1,0.01)\n",
    "    Y = norm.pdf(X,0,sigma)\n",
    "    h = 1/Y[0]*max_step\n",
    "    Y = Y*h\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label付けする関数. ipsなら赤が1, 緑が2, 青が3のmapにする. melanomaは0か1\n",
    "#mask_array...mask画像\n",
    "#data...\"ips\"or\"melanoma\"\n",
    "def get_ytrue(mask_array, data):\n",
    "        if data == \"ips\":\n",
    "            height, width, _ = mask_array.shape\n",
    "            good_label = ((mask_array[:,:,0] == 255)&\n",
    "                          (mask_array[:,:,1] == 0)&\n",
    "                          (mask_array[:,:,2] == 0)\n",
    "                         ) * np.ones((height, width)) * 1\n",
    "            bad_label = ((mask_array[:,:,0] == 0)&\n",
    "                         (mask_array[:,:,1] == 255)&\n",
    "                         (mask_array[:,:,2] == 0)\n",
    "                        ) * np.ones((height, width)) * 2\n",
    "            bgd_label = ((mask_array[:,:,0] == 0)&\n",
    "                         (mask_array[:,:,1] == 0)&\n",
    "                         (mask_array[:,:,2] == 255)\n",
    "                        ) * np.ones((height, width)) * 3\n",
    "            y_true = good_label + bad_label + bgd_label\n",
    "            return y_true\n",
    "        else:\n",
    "            height, width = mask_array.shape\n",
    "            y_true = (mask_array == 255) * np.ones((height, width))\n",
    "            return y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_data_path_load(path):#一つ前のCurriculumでのuncertainty mapをloadする関数\n",
    "    img_path=[]\n",
    "    if data in ['ips', 'melanoma']:\n",
    "        for x in os.listdir(path):\n",
    "            img_path.append(path+x)\n",
    "        return img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "0\n",
      "[[255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]\n",
      " ...\n",
      " [255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-fe8601461af1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m600\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'a' is not defined"
     ]
    }
   ],
   "source": [
    "#メラノーマの等間隔でのpatchの切り出し\n",
    "number=0\n",
    "step=130\n",
    "data='melanoma'\n",
    "patch_size=160\n",
    "for data_num in [1,2,3,4,5]:\n",
    "    for w in ['train']:#'train','test'\n",
    "        m=0\n",
    "        print(w)\n",
    "        #画像path読み込み\n",
    "        img_list, mask_list = tl.data_path_load(data,w,data_num)\n",
    "        img_list.sort()\n",
    "        mask_list.sort()\n",
    "        for i_path, m_path in zip(img_list, mask_list):         \n",
    "            my_makedirs('/home/sora/new_project/crop/dataset_%d/%s/'%(data_num,w))\n",
    "            y=0\n",
    "            if number % 100 ==0:\n",
    "                print(number)\n",
    "            number+=1\n",
    "            #画像読み込み\n",
    "            m_mask = cv2.imread(m_path)\n",
    "            m_mask = cv2.cvtColor(m_mask, cv2.COLOR_BGR2RGB)\n",
    "            height, width = m_mask.shape[:2]\n",
    "\n",
    "            img = Image.open(i_path)\n",
    "            img = np.array(img)\n",
    "\n",
    "            while y < (height - patch_size + 1):\n",
    "                x = 0\n",
    "                while x < (width - patch_size + 1):\n",
    "                    list=[]\n",
    "                    crop_mask = m_mask[y:patch_size+y, x:patch_size+x]\n",
    "                    crop_img = img[y:patch_size+y, x:patch_size+x] \n",
    "                    crop_mask = crop_mask/255\n",
    "                    crop_img = crop_img/255.\n",
    "                    \n",
    "                    #教師ラベル作成. 0, 1チャネルをlabelに使う\n",
    "                    tmp=np.ones((patch_size,patch_size,3))\n",
    "                    tmp[crop_mask==1]=0#３次元配列のチャネル0に黒い部分を1とした１次元行列を代入\n",
    "                    tmp[:,:,1]=crop_mask[:,:,0]#３次元配列のチャネル1に白い部分を1とした１次元行列を代入\n",
    "\n",
    "                    x+=step\n",
    "\n",
    "                    list.append(crop_img)\n",
    "                    list.append(tmp)\n",
    "                    np.save('/home/sora/new_project/crop/dataset_%d/%s/input%d.npy' %(data_num,w,m), np.array(list))\n",
    "                    m+=1\n",
    "                    del list,tmp,crop_img,crop_mask\n",
    "                    gc.collect()\n",
    "                y+=step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number=0\n",
    "dist = gaussian_dist(sigma, max_step)#正規分布作成\n",
    "step=120\n",
    "data='melanoma'\n",
    "patch_size=160\n",
    "for data_num in [3,4,5]:\n",
    "    for w in ['train']:#'train','test'\n",
    "        n=0\n",
    "        m=0\n",
    "        print(w)\n",
    "        path=(\"./%s/%s/%s/size_%d/dataset_%d/%s_un/uncertainty_T_0.5/\" %(data, method,model_name,patch_size,data_num,w))\n",
    "        img_list, mask_list = tl.data_path_load(data,w,data_num)#画像のpathを取得\n",
    "        pre_list = pre_data_path_load(path)\n",
    "        img_list.sort()\n",
    "        mask_list.sort()\n",
    "        pre_list.sort()\n",
    "        for i_path, m_path,p_path in zip(img_list, mask_list, pre_list): \n",
    "            my_makedirs('/home/sora/new_project/crop/dataset_%d/%s/'%(data_num,w))\n",
    "            y=0\n",
    "            if number % 50 == 0:\n",
    "                print(number)\n",
    "            number+=1\n",
    "            m_mask = cv2.imread(m_path)\n",
    "            m_mask = cv2.cvtColor(m_mask, cv2.COLOR_BGR2RGB)\n",
    "            height, width = m_mask.shape[:2]\n",
    "\n",
    "            img = Image.open(i_path)\n",
    "            img = np.array(img)\n",
    "\n",
    "            p_image = cv2.imread(p_path)#uncertainty map load\n",
    "            p_image = cv2.cvtColor(p_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            while y < (height - patch_size + 1):\n",
    "                x = 0\n",
    "                while x < (width - patch_size + 1):\n",
    "                    list=[]\n",
    "                    crop_mask = m_mask[y:patch_size+y, x:patch_size+x]\n",
    "\n",
    "                    crop_img = img[y:patch_size+y, x:patch_size+x]  \n",
    "                    crop_p = p_image[y:patch_size+y, x:patch_size+x]\n",
    "\n",
    "                    crop_mask = crop_mask/255\n",
    "                    crop_img = crop_img/255.\n",
    "\n",
    "                    tmp=np.ones((patch_size,patch_size,3))\n",
    "                    tmp[crop_mask==1]=0\n",
    "                    tmp[:,:,1]=crop_mask[:,:,1]\n",
    "\n",
    "                    e = np.count_nonzero(crop_p[:,:,0] == 255)/(patch_size*patch_size)#uncertainty map の白い部分の割合を計算\n",
    "                    e = round(e, 3)\n",
    "                    if e == 1:\n",
    "                        e = 0.999\n",
    "                    x_step = int(dist[int(e*100)])\n",
    "                    x+=x_step\n",
    "                    list.append(crop_img)\n",
    "                    list.append(tmp)\n",
    "\n",
    "                    np.save('/home/sora/new_project/crop/dataset_%d/%s/input%d.npy' %(data_num,w,m), np.array(list))\n",
    "                    m+=1\n",
    "                    del list,crop_img,crop_mask,crop_p\n",
    "                    gc.collect()\n",
    "                y+=step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#melanoma画像の縦、横の短い方のピクセル幅に合わせてpatchを切り出す\n",
    "number=0\n",
    "for w in ['train','val']:#'train','test'\n",
    "    m=0\n",
    "    print(w)\n",
    "    img_list, mask_list = tl.data_path_load(data,w,data_num)\n",
    "    img_list.sort()\n",
    "    mask_list.sort()\n",
    "    for i_path, m_path in zip(img_list, mask_list):         \n",
    "        #my_makedirs('/home/sora/new_project/crop/%s/inputup'%w)\n",
    "        my_makedirs('/home/sora/new_project/crop/%s/inputdown'%w)\n",
    "        y=0\n",
    "        if number % 100 ==0:\n",
    "            print(number)\n",
    "        number+=1\n",
    "        m_mask = cv2.imread(m_path)\n",
    "        m_mask = cv2.cvtColor(m_mask, cv2.COLOR_BGR2RGB)\n",
    "        height, width = m_mask.shape[:2]\n",
    "        #mask = Image.open(m_path)\n",
    "        #height, width = m_mask.size\n",
    "        #mask = np.array(mask)\n",
    "        if height < width:\n",
    "            step = width-height\n",
    "            size = height\n",
    "        elif height > width:\n",
    "            step = height-width\n",
    "            size = width\n",
    "        else:\n",
    "            step=10\n",
    "            size = width\n",
    "        img = Image.open(i_path)\n",
    "        img = np.array(img)\n",
    "         \n",
    "        while y < (height - size + 1):\n",
    "            x = 0\n",
    "            while x < (width - size + 1):\n",
    "                list=[]\n",
    "                crop_mask = m_mask[y:size+y, x:size+x]\n",
    "                crop_img = img[y:size+y, x:size+x] \n",
    "                \n",
    "\n",
    "                \n",
    "                crop_img = Image.fromarray(crop_img)\n",
    "                crop_mask = Image.fromarray(crop_mask)\n",
    "                crop_img = crop_img.resize((patch_size,patch_size))\n",
    "                crop_mask = crop_mask.resize((patch_size,patch_size))\n",
    "                \n",
    "                crop_img = np.array(crop_img)\n",
    "                crop_mask = np.array(crop_mask)\n",
    "                crop_mask = crop_mask/255\n",
    "                crop_img = crop_img/255.\n",
    "                crop_mask[crop_mask>0]=1\n",
    "                \n",
    "                tmp=np.ones((patch_size,patch_size,3))\n",
    "                tmp[crop_mask==1]=0\n",
    "                tmp[:,:,1]=crop_mask[:,:,0]\n",
    "                \n",
    "                x+=step\n",
    "                \n",
    "                list.append(img)\n",
    "                list.append(tmp)\n",
    "                np.save('/home/sora/new_project/crop/%s/inputdown/inputdown_%d.npy' %(w,m), np.array(list))\n",
    "                m+=1\n",
    "            y+=step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
